{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ref\n",
    "\n",
    "[Challenges with music identification - Random Prrojection and LSH](https://github.com/santhoshhari/Locality-Sensitive-Hashing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Projection\n",
    "\n",
    "representing high-demensional data in low-dimentional feature space\n",
    "\n",
    "It gained traction for its ability to approximately preserve relations(pairwise distance or cosine similarity)\n",
    "\n",
    "\n",
    "Notations : \n",
    "\n",
    "1. high-demensional data $D_{d \\times n}$ -  (dimensions $d$, observations $n$)\n",
    "\n",
    "2. porjections $P_{k \\times n}$ - (dimensions $k$, observations $n$)\n",
    "\n",
    "3. random projection matrix $R_{k \\times d}$ - (low dimensions $k$, high dimensions $d$)\n",
    "\n",
    "where $k << d$\n",
    "\n",
    "$R_{k \\times d}$ are called random vectors and the elements of these random vectors are drawn indenpendently from gaussion distribution(zero mean, unit variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSH using Random Projection Method\n",
    "\n",
    "construct a table of all possible bins where\n",
    "\n",
    "1. each bins is made up of similar items\n",
    "\n",
    "2. each bin can be represented by bitwise hash value\n",
    "\n",
    "3. which is a nunber made up of sequence of 1's and 0's(e.g. 110110, 111001)\n",
    "\n",
    "In this representation, two observations with same bitwise hash values are more likely to be similar than those with different hashes\n",
    "\n",
    "Algo\n",
    "\n",
    "<br>\n",
    "\n",
    "1. Create `k` random vectors of length `d` each, where `k` is the size of bitwiese hash values and `d` is the dimension of the feature vector (the hash_size is the same as low-dimension k)\n",
    "\n",
    "<br>\n",
    "\n",
    "2. For each random vector, compute the `dot product` of the random vector and the observations. If the result of the dot product is positive, assign the bit values as 1 else 0\n",
    "\n",
    "<br>\n",
    "\n",
    "3. Concatenate all the bit values computed for `k` dot products\n",
    "\n",
    "<br>\n",
    "\n",
    "4. Repeat the above two steps for all observations to compute hash values\n",
    "\n",
    "<br>\n",
    "\n",
    "5. Group observations with same hash values together to create a LSH table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T13:11:16.843069Z",
     "start_time": "2021-06-06T13:11:16.810834Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T14:53:30.057625Z",
     "start_time": "2021-06-06T14:53:30.044690Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:24:46.466783Z",
     "start_time": "2021-06-06T15:24:46.448517Z"
    }
   },
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "    def __init__(self, hash_size : int, input_dimensions : int) -> None:\n",
    "        self.hash_size = hash_size\n",
    "        self.input_dimensions = input_dimensions\n",
    "        self.hash_table = defaultdict(dict)\n",
    "        # projections R_{k x d}\n",
    "        self.projections = np.random.rand(self.hash_size, self.input_dimensions)\n",
    "    \n",
    "    def generate_hash(self, input_vector : np.ndarray) -> str:\n",
    "        bools = (np.dot(input_vector, self.projections.T) > 0).astype('int')\n",
    "        return ''.join(bools.astype('str'))\n",
    "        \n",
    "    def __setitem__(self, label, input_vector : np.ndarray) -> None:\n",
    "        hash_value = self.generate_hash(input_vector)\n",
    "        self.hash_table[hash_value][label] = input_vector\n",
    "        \n",
    "    def __getitem__(self, hash_code : str) -> dict:\n",
    "        return self.hash_table[hash_code]\n",
    "    \n",
    "    def __repr__(self) -> None:\n",
    "        return self.hash_table.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:24:46.844762Z",
     "start_time": "2021-06-06T15:24:46.831234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.60644632  0.20346364 -0.75635075 -1.42225371 -0.64657288]\n",
      "[-1.081548    1.68714164  0.88163976 -0.00797264  1.47994414]\n",
      "[ 0.07736831 -0.8612842   1.52312408  0.53891004 -1.03724615]\n"
     ]
    }
   ],
   "source": [
    "vec1 = np.random.randn(5)\n",
    "vec2 = np.random.randn(5)\n",
    "vec3 = np.random.randn(5)\n",
    "print(vec1, vec2, vec3, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:24:47.141265Z",
     "start_time": "2021-06-06T15:24:47.125410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19033868, -0.87561825, -1.38279973,  0.92617755,  1.90941664],\n",
       "       [-1.39856757,  0.56296924, -0.65064257, -0.48712538, -0.59239392]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k=4, d=20\n",
    "projections = np.random.randn(2, 5)\n",
    "projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:24:47.353364Z",
     "start_time": "2021-06-06T15:24:47.337180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_1\n",
      "[0 1]\n",
      "01\n",
      "\n",
      "v_2\n",
      "[1 1]\n",
      "11\n",
      "\n",
      "v_3\n",
      "[0 0]\n",
      "00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx,v in enumerate([vec1, vec2, vec3]):\n",
    "    \n",
    "    bools = (np.dot(v, projections.T) > 0).astype('int')\n",
    "    hash_code = ''.join(bools.astype('str'))\n",
    "\n",
    "    print(f'v_{idx+1}',bools, hash_code, sep='\\n')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:24:47.698979Z",
     "start_time": "2021-06-06T15:24:47.684125Z"
    }
   },
   "outputs": [],
   "source": [
    "def cos_sim(vec1 : np.ndarray, vec2 : np.ndarray) -> float:\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1)*np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:24:48.115762Z",
     "start_time": "2021-06-06T15:24:48.100846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07465665021191253, -0.3095602328229634, -0.31148046840627885)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(vec1, vec2), cos_sim(vec1, vec3), cos_sim(vec2, vec3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hash code really preserve similarity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:24:48.831846Z",
     "start_time": "2021-06-06T15:24:48.817130Z"
    }
   },
   "outputs": [],
   "source": [
    "random_projection_hash = HashTable(hash_size=2, input_dimensions=5)\n",
    "\n",
    "for idx,v in enumerate([vec1, vec2, vec3]):\n",
    "    random_projection_hash[f'vec_{idx + 1}'] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:24:49.322289Z",
     "start_time": "2021-06-06T15:24:49.307038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'00': {'vec_1': array([-1.60644632,  0.20346364, -0.75635075, -1.42225371, -0.64657288])}, '11': {'vec_2': array([-1.081548  ,  1.68714164,  0.88163976, -0.00797264,  1.47994414])}, '01': {'vec_3': array([ 0.07736831, -0.8612842 ,  1.52312408,  0.53891004, -1.03724615])}})\n"
     ]
    }
   ],
   "source": [
    "print(random_projection_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:24:50.612827Z",
     "start_time": "2021-06-06T15:24:50.597334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vec_1': array([-1.60644632,  0.20346364, -0.75635075, -1.42225371, -0.64657288])}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_projection_hash['00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:24:50.819370Z",
     "start_time": "2021-06-06T15:24:50.806648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vec_3': array([ 0.07736831, -0.8612842 ,  1.52312408,  0.53891004, -1.03724615])}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_projection_hash['01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:24:51.010932Z",
     "start_time": "2021-06-06T15:24:50.995308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vec_2': array([-1.081548  ,  1.68714164,  0.88163976, -0.00797264,  1.47994414])}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_projection_hash['11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intuition behind this idea is that \n",
    "\n",
    "1. if two points are aligned completely, i.e have perfect correlation from origin, they will be in the same hash bin\n",
    "\n",
    "2. if two points separated by 180 degrees will be in different bins\n",
    "\n",
    "3. two points 90 degrees aprar have 50% probability to be in the same bins\n",
    "\n",
    "\n",
    "Due to the randomness, it is not likely that all similar item are grouped correctly. \n",
    "\n",
    "To overcome this limitation, a common practice is to create multiple hash tables and consider an observation `a` to be simiar to `b`\n",
    "\n",
    "**If they are in same bin in at least one of the tables**\n",
    "\n",
    "Below is the code snippet to construct multiple hash tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:25:35.718669Z",
     "start_time": "2021-06-06T15:25:35.701852Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, num_tables : int, hash_size : int, input_dimensions : int):\n",
    "        self.num_tables = num_tables\n",
    "        self.hash_size = hash_size\n",
    "        self.input_dimensions = input_dimensions\n",
    "        self.tables = []\n",
    "        for i in range(self.num_tables):\n",
    "            self.tables.append(\n",
    "                HashTable(self.hash_size, self.input_dimensions)\n",
    "            )\n",
    "    def __setitem__(self, label : str, input_vector : np.ndarray):\n",
    "        for t in self.tables:\n",
    "            t[label] = input_vector\n",
    "    \n",
    "    def __getitem__(self, label) -> list:\n",
    "        res = []\n",
    "        for t in self.tables:\n",
    "            res.extend(t[label])\n",
    "        return list(set(res))\n",
    "    def __repr__(self):\n",
    "        return self.tables.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:25:35.859572Z",
     "start_time": "2021-06-06T15:25:35.821811Z"
    }
   },
   "outputs": [],
   "source": [
    "lsh = LSH(num_tables=3, hash_size=2, input_dimensions=5)\n",
    "# random_projection_hash = HashTable(hash_size=2, input_dimensions=5)\n",
    "\n",
    "for idx,v in enumerate([vec1, vec2, vec3]):\n",
    "    lsh[f'vec_{idx + 1}'] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:26:51.986148Z",
     "start_time": "2021-06-06T15:26:51.968827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'00': {'vec_1': array([-1.60644632,  0.20346364, -0.75635075, -1.42225371, -0.64657288])}, '11': {'vec_2': array([-1.081548  ,  1.68714164,  0.88163976, -0.00797264,  1.47994414]), 'vec_3': array([ 0.07736831, -0.8612842 ,  1.52312408,  0.53891004, -1.03724615])}, '01': {}, 'vec_1': {}})\n",
      "\n",
      "defaultdict(<class 'dict'>, {'00': {'vec_1': array([-1.60644632,  0.20346364, -0.75635075, -1.42225371, -0.64657288])}, '11': {'vec_2': array([-1.081548  ,  1.68714164,  0.88163976, -0.00797264,  1.47994414]), 'vec_3': array([ 0.07736831, -0.8612842 ,  1.52312408,  0.53891004, -1.03724615])}, '01': {}, 'vec_1': {}})\n",
      "\n",
      "defaultdict(<class 'dict'>, {'00': {'vec_1': array([-1.60644632,  0.20346364, -0.75635075, -1.42225371, -0.64657288])}, '11': {'vec_2': array([-1.081548  ,  1.68714164,  0.88163976, -0.00797264,  1.47994414]), 'vec_3': array([ 0.07736831, -0.8612842 ,  1.52312408,  0.53891004, -1.03724615])}, '01': {}, 'vec_1': {}})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in lsh.tables:\n",
    "    print(t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "1. figure out **If they are in same bin in at least one of the tables**\n",
    "\n",
    "2. get LSH class work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_tf231",
   "language": "python",
   "name": "py37_tf231"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
