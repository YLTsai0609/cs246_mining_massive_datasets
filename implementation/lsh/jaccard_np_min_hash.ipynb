{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSH\n",
    "\n",
    "python implementation of LSH\n",
    "\n",
    "dataset\n",
    "\n",
    "4 articles pulled from CNN\n",
    "\n",
    "concatenation of 3 of those, this one artificialy produce some high similarity scores\n",
    "\n",
    "outline\n",
    "\n",
    "## Part I: computing similarity amongst text documents\n",
    "1. Introduce a shingle function. Clean and split each text file into a set of K-shingles\n",
    "2. Compute the exact Jaccard similarity (intersection over union) between all pairs\n",
    "3. Create and apply a MinHashing class:\n",
    "    1. Initialize with a dictionary of key-value pairs for the shingles\n",
    "    2. Apply \"universal hashing\" to perform minhashing on a shingle set\n",
    "    3. can be called like a function to compute a **signature matrix**\n",
    "4. Evaluate MinHashing effectiveness by computing scores of all pairs\n",
    "5. Introduce LSH for finding **candidate pairs**, i.e. use a banded signature matrix to find all pairs whose similarity is likely above a threshold\n",
    "6. Make this efficient, by using hash table for band, column ids, allowing O(n) comparison\n",
    "\n",
    "## Part II: computing similarity amongst vectors\n",
    "\n",
    "* Afterwards, we provide an additional LSH family for Euclidean spaces, namely cosine similarity. \n",
    "* This is used to ascertain the similarity of vectors in a D-dimensional space.\n",
    "* Can be implemented using the *Random Hyperplanes* hashing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:02:48.769779Z",
     "start_time": "2021-06-07T15:02:48.752357Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import collections\n",
    "import numpy as np\n",
    "from os.path import join as PJ\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: computing similarity amongst text documents\n",
    "\n",
    "## Shingling\n",
    "\n",
    "1. Create k shingles of for each document\n",
    "2. Calculate total shingles,\n",
    "3. Conaider Input Matrix (Shingles x documents) -  $I_{S \\times D}$\n",
    "4. Create MinHasher(the minsh hash object)\n",
    "6. Hash the document into Signature Matrix - $M_{\\alpha \\times D}$\n",
    "\n",
    "where $\\alpha$ is the `n_signature`, you should make $\\alpha << S$\n",
    "\n",
    "Because we do min-hashing do preserve the similarity of Jaccard Similarity\n",
    "and do the dimension reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:58:45.307681Z",
     "start_time": "2021-06-07T14:58:45.227277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joetsai/work/yulong/cs246_mining_massive_datasets/implementation/lsh\n",
      "/home/joetsai/work/yulong/cs246_mining_massive_datasets/implementation/lsh/data/sampledocs_jaccard\n",
      "Average char-length: 3651.6\n",
      "Min char-length: 2412\n",
      "Max char-length: 5873\n"
     ]
    }
   ],
   "source": [
    "\n",
    "HOME = os.getcwd()\n",
    "TARGET = os.path.join(HOME,'data', 'sampledocs_jaccard')\n",
    "\n",
    "print(HOME,TARGET, sep='\\n')\n",
    "\n",
    "documents = []\n",
    "for article in os.listdir(TARGET):\n",
    "    if article == 'stopwords':\n",
    "        continue\n",
    "    path = os.path.join(TARGET, article)\n",
    "    with open(path, 'r') as file:\n",
    "        documents.append(file.read())\n",
    "        \n",
    "stopwords = []\n",
    "with open(os.path.join(TARGET, 'stopwords'), 'r') as file:\n",
    "    for line in file:\n",
    "        stopwords.append(line.strip())\n",
    "        \n",
    "for i, doc in enumerate(documents):\n",
    "    doc = doc.strip().replace('\\n', ' ').lower()\n",
    "    for word in stopwords:\n",
    "        doc = doc.replace(' '+word+' ', ' ')\n",
    "    documents[i] = doc\n",
    "\n",
    "print(f\"Average char-length: \\\n",
    "{np.mean(np.array([len(x) for x in documents]))}\")\n",
    "print(f\"Min char-length: {min(len(x) for x in documents)}\")\n",
    "print(f\"Max char-length: {max(len(x) for x in documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:58:46.151470Z",
     "start_time": "2021-06-07T14:58:46.135120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2782 unique shingles, out of 3673 possible.\n",
      "Found 2091 unique shingles, out of 3291 possible.\n",
      "Found 1918 unique shingles, out of 2412 possible.\n",
      "Found 3953 unique shingles, out of 5873 possible.\n",
      "Found 2060 unique shingles, out of 3009 possible.\n"
     ]
    }
   ],
   "source": [
    "# create K-shingles by sliding window approach\n",
    "# TODO [joe] - make this sparse matrix\n",
    "def getShingles(str1, K=5):\n",
    "    d1 = set()\n",
    "    for i in range(len(str1)-K):\n",
    "        d1.add(str1[i:i+K])\n",
    "    print(f\"Found {len(d1)} unique shingles, out of {len(str1)} possible.\")\n",
    "    return d1\n",
    "doc_shingles = [getShingles(s, 5) for s in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:59:07.040749Z",
     "start_time": "2021-06-07T14:59:07.023940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**~~~~~~ True similarity scores ~~~~~~**\n",
      "Pair\tScore\n",
      "--------------\n",
      "(0, 1)\t0.081\n",
      "(0, 2)\t0.052\n",
      "(0, 3)\t0.083\n",
      "(0, 4)\t0.069\n",
      "(1, 2)\t0.051\n",
      "(1, 3)\t0.294\n",
      "(1, 4)\t0.093\n",
      "(2, 3)\t0.400\n",
      "(2, 4)\t0.050\n",
      "(3, 4)\t0.336\n"
     ]
    }
   ],
   "source": [
    "def jaccardSim(d1,d2):\n",
    "    return len(d1.intersection(d2))/len(d1.union(d2))\n",
    "\n",
    "# itertools.combinations finds all (,n) n-pairs\n",
    "# then we use a map op on the tuples with jaccardSim\n",
    "pairs = itertools.combinations(documents, 2)\n",
    "pair_labels = []\n",
    "pair_sims = []\n",
    "for x1, x2 in itertools.combinations(zip(range(len(doc_shingles)),doc_shingles), 2):\n",
    "    pair_labels.append((x1[0],x2[0]))\n",
    "    pair_sims.append(jaccardSim(x1[1],x2[1]))\n",
    "    \n",
    "print(f\"**~~~~~~ True similarity scores ~~~~~~**\")\n",
    "print(\"Pair\\tScore\")\n",
    "print(\"-\"*14)\n",
    "for pair, score in zip(pair_labels, pair_sims):\n",
    "    print(f\"{pair}\\t{score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:59:42.554547Z",
     "start_time": "2021-06-07T14:59:42.542308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7534 shingles\n"
     ]
    }
   ],
   "source": [
    "# Take union of all sets. Convert to an array and assign\n",
    "# each element an integer based on position in array\n",
    "fullset = set.union(*doc_shingles)\n",
    "shingle_dict = dict(zip(list(fullset),range(len(fullset))))\n",
    "print(f\"There are {len(shingle_dict)} shingles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:46:39.986022Z",
     "start_time": "2021-06-07T15:46:29.952920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'far a',\n",
       " 'e maj',\n",
       " 'ecede',\n",
       " 'reats',\n",
       " 'onall',\n",
       " 'd the',\n",
       " 'olora',\n",
       " 's. pa',\n",
       " 'ies, ',\n",
       " 'ult e',\n",
       " 'oaths',\n",
       " 'in. w',\n",
       " 'withi',\n",
       " 'f. fe',\n",
       " ' prep',\n",
       " 'edenc',\n",
       " 'r arg',\n",
       " 's, pe',\n",
       " 'lecte',\n",
       " 'kgrou',\n",
       " ' trum',\n",
       " 'udici',\n",
       " 'irmly',\n",
       " 'p gon',\n",
       " 'hilli',\n",
       " 'fice ',\n",
       " 'imed ',\n",
       " 'us, t',\n",
       " \"'s vi\",\n",
       " 'rivol',\n",
       " ' blat',\n",
       " 's ben',\n",
       " 'd tv ',\n",
       " 'ane u',\n",
       " 'ness,',\n",
       " ' powe',\n",
       " 'atitu',\n",
       " 'date ',\n",
       " ' one ',\n",
       " 'own e',\n",
       " '\" cou',\n",
       " 'vote ',\n",
       " 's cha',\n",
       " 'ng co',\n",
       " 's too',\n",
       " ', dis',\n",
       " 'mselv',\n",
       " 'feroc',\n",
       " 'fully',\n",
       " ' floo',\n",
       " 'rges ',\n",
       " 'far, ',\n",
       " 'epost',\n",
       " 'aimed',\n",
       " ', als',\n",
       " 'order',\n",
       " 'crede',\n",
       " ' back',\n",
       " 'es la',\n",
       " 'micus',\n",
       " 'ults,',\n",
       " 'gious',\n",
       " 'litic',\n",
       " 'ent, ',\n",
       " 'ieved',\n",
       " 'ry pe',\n",
       " 'use f',\n",
       " 'led w',\n",
       " 'w oat',\n",
       " 'ure w',\n",
       " '- cou',\n",
       " 'g, re',\n",
       " 'may s',\n",
       " 'ures ',\n",
       " 'ected',\n",
       " 'serva',\n",
       " ' prim',\n",
       " 'oney ',\n",
       " 'y tra',\n",
       " 't.alm',\n",
       " 'ember',\n",
       " 'normo',\n",
       " '. tru',\n",
       " 's sta',\n",
       " 'here ',\n",
       " 'ns ju',\n",
       " 'epubl',\n",
       " 'rged ',\n",
       " 'ent-e',\n",
       " 'onal ',\n",
       " 'eful,',\n",
       " 'e fri',\n",
       " 'assau',\n",
       " 'e law',\n",
       " 'anyon',\n",
       " 'untry',\n",
       " 'ed jo',\n",
       " 'n cre',\n",
       " 'profa',\n",
       " 'den l',\n",
       " 'eople',\n",
       " 'nts, ',\n",
       " 'ge de',\n",
       " 'ion r',\n",
       " 'd wit',\n",
       " 'p ref',\n",
       " 'mes d',\n",
       " 'us, g',\n",
       " 'nd ma',\n",
       " '. cou',\n",
       " 'dire ',\n",
       " 'volou',\n",
       " 'onald',\n",
       " 'catio',\n",
       " 'ys tr',\n",
       " 'ushin',\n",
       " 'n hou',\n",
       " 'nally',\n",
       " ' cryi',\n",
       " 'e far',\n",
       " 'ish o',\n",
       " 'oliti',\n",
       " 'an me',\n",
       " 'last ',\n",
       " 'ic ge',\n",
       " 'ifull',\n",
       " 'nt do',\n",
       " 'use s',\n",
       " 'n \"co',\n",
       " 'ents,',\n",
       " 'ge ev',\n",
       " 'nesse',\n",
       " 'ased ',\n",
       " 'uld f',\n",
       " 'o, go',\n",
       " 'floor',\n",
       " 'ngnes',\n",
       " 'nd la',\n",
       " 'on el',\n",
       " 'n res',\n",
       " 'e dem',\n",
       " ' clea',\n",
       " 'orked',\n",
       " 'n urg',\n",
       " ' list',\n",
       " 'e tri',\n",
       " 'teste',\n",
       " 'siden',\n",
       " 'n amy',\n",
       " 'ul ge',\n",
       " 'spiri',\n",
       " 'sive ',\n",
       " 'peopl',\n",
       " 'le, l',\n",
       " 'isput',\n",
       " 'resid',\n",
       " 's, le',\n",
       " 'ywher',\n",
       " 'ate l',\n",
       " 'orabl',\n",
       " '. con',\n",
       " 'time ',\n",
       " 'ur fi',\n",
       " 'an ho',\n",
       " 'judge',\n",
       " 'ant l',\n",
       " 'shing',\n",
       " 'ud tv',\n",
       " ' -- m',\n",
       " 'gues ',\n",
       " 'fane ',\n",
       " 'faile',\n",
       " 'age b',\n",
       " 'ious,',\n",
       " 'tt, w',\n",
       " 'e els',\n",
       " 'egal ',\n",
       " ' amon',\n",
       " 'ing c',\n",
       " 'aths ',\n",
       " 'arges',\n",
       " 'kly c',\n",
       " 'thele',\n",
       " 'rtify',\n",
       " 'ntinu',\n",
       " 'aud t',\n",
       " 'deway',\n",
       " 'lined',\n",
       " 'e sup',\n",
       " 'dermi',\n",
       " 'frivo',\n",
       " 'ief s',\n",
       " 'deral',\n",
       " 'story',\n",
       " 'rve g',\n",
       " 'p tos',\n",
       " ' supp',\n",
       " 'law r',\n",
       " 'ast) ',\n",
       " 'et ch',\n",
       " 'ote. ',\n",
       " 'earfu',\n",
       " 'st ch',\n",
       " ' atte',\n",
       " 'y cou',\n",
       " 'ng pr',\n",
       " 'ans a',\n",
       " 'eague',\n",
       " 'ce, g',\n",
       " 'issed',\n",
       " 'perso',\n",
       " 'hotho',\n",
       " '- mid',\n",
       " ' yes,',\n",
       " ' giul',\n",
       " ' toss',\n",
       " 'etrib',\n",
       " 'eers ',\n",
       " 's, as',\n",
       " 'iled ',\n",
       " ', rec',\n",
       " 'ibuti',\n",
       " 'n beh',\n",
       " 'atant',\n",
       " 'me ta',\n",
       " 'nish ',\n",
       " 'nance',\n",
       " 's ris',\n",
       " ' gove',\n",
       " 'ws ri',\n",
       " 'ey ge',\n",
       " 'urd l',\n",
       " ' insp',\n",
       " 'mmari',\n",
       " ' hope',\n",
       " 'gue r',\n",
       " 'nuine',\n",
       " 'cy be',\n",
       " 'ces a',\n",
       " '-- ap',\n",
       " 'or ma',\n",
       " ' stat',\n",
       " 's jud',\n",
       " 'agues',\n",
       " '-- su',\n",
       " 'ce. r',\n",
       " 've ch',\n",
       " 'nors ',\n",
       " ' cost',\n",
       " 't ele',\n",
       " 'ways ',\n",
       " 'fail ',\n",
       " ' foll',\n",
       " 'equen',\n",
       " 'secre',\n",
       " 'ctors',\n",
       " 'ls ac',\n",
       " 'm deb',\n",
       " ' coul',\n",
       " 'ng fi',\n",
       " 'dent ',\n",
       " 'ntimi',\n",
       " 'eathe',\n",
       " 's eve',\n",
       " 'requi',\n",
       " 'iden ',\n",
       " ' evid',\n",
       " ' char',\n",
       " 'jorit',\n",
       " 'every',\n",
       " 'end t',\n",
       " 'en ac',\n",
       " 'simpl',\n",
       " 'tage ',\n",
       " 'rage,',\n",
       " 'te re',\n",
       " 'nment',\n",
       " 'made ',\n",
       " 'there',\n",
       " 'uppor',\n",
       " 'ing f',\n",
       " 'd car',\n",
       " ' symb',\n",
       " 'andfu',\n",
       " ' orde',\n",
       " 'rve c',\n",
       " 'rse d',\n",
       " 'ilenc',\n",
       " 'rying',\n",
       " ' trac',\n",
       " ' urgi',\n",
       " 'less,',\n",
       " 'could',\n",
       " 'te fr',\n",
       " ' prof',\n",
       " 'ed em',\n",
       " 'oneth',\n",
       " ' resp',\n",
       " 'harge',\n",
       " 'wsuit',\n",
       " ' duty',\n",
       " ' law ',\n",
       " 'holde',\n",
       " ' stuf',\n",
       " 'd. su',\n",
       " 'y ame',\n",
       " ' fear',\n",
       " 's per',\n",
       " 'xas, ',\n",
       " 'rage\"',\n",
       " ' awai',\n",
       " 'palli',\n",
       " 'ges -',\n",
       " 'nsiti',\n",
       " 'ies l',\n",
       " 'e jus',\n",
       " 'id. t',\n",
       " 'loor ',\n",
       " 'n eno',\n",
       " 'tarni',\n",
       " 'oup r',\n",
       " 'on au',\n",
       " 'ies b',\n",
       " ' way.',\n",
       " 'mp --',\n",
       " 'rdice',\n",
       " 'mands',\n",
       " 'e ele',\n",
       " 'ule l',\n",
       " 'wn en',\n",
       " 'ng ab',\n",
       " 'nows ',\n",
       " 'd aro',\n",
       " 'te, i',\n",
       " 'on. s',\n",
       " 'dged ',\n",
       " 'iven ',\n",
       " 'rvers',\n",
       " 'y. it',\n",
       " 'ted e',\n",
       " 'use r',\n",
       " 'ope i',\n",
       " 'oyali',\n",
       " 't cha',\n",
       " 's, co',\n",
       " 'despe',\n",
       " 'yes, ',\n",
       " 'e tru',\n",
       " 'd (so',\n",
       " 'pend ',\n",
       " ' want',\n",
       " 'nsive',\n",
       " 'n fin',\n",
       " ' anot',\n",
       " 'ed de',\n",
       " 'ar ar',\n",
       " 'nd ru',\n",
       " 'can h',\n",
       " ' requ',\n",
       " 's wor',\n",
       " 'nowle',\n",
       " ' none',\n",
       " 'rn re',\n",
       " 'lly c',\n",
       " 'w thr',\n",
       " 'lists',\n",
       " 'erate',\n",
       " 'mehow',\n",
       " 'chill',\n",
       " 'cular',\n",
       " 'ess, ',\n",
       " 'ery p',\n",
       " 'cting',\n",
       " 'rful ',\n",
       " 'later',\n",
       " 'shed ',\n",
       " 'es ur',\n",
       " 'rep. ',\n",
       " ' pers',\n",
       " 'lts f',\n",
       " ' reco',\n",
       " 'silen',\n",
       " 'aroun',\n",
       " 'ns co',\n",
       " 'ion s',\n",
       " 'nce t',\n",
       " 'e cre',\n",
       " 'gal t',\n",
       " 'ors c',\n",
       " 'uth p',\n",
       " 'iat. ',\n",
       " 'r. do',\n",
       " 'nce r',\n",
       " 'vows ',\n",
       " 'l ele',\n",
       " 'lves,',\n",
       " 'areer',\n",
       " 'ate, ',\n",
       " 'oster',\n",
       " 'lated',\n",
       " ' patr',\n",
       " ' nine',\n",
       " 'tes t',\n",
       " 'nning',\n",
       " 'rty, ',\n",
       " ' may ',\n",
       " 'final',\n",
       " 'ed. s',\n",
       " ' john',\n",
       " 'ths o',\n",
       " ' occu',\n",
       " ' mids',\n",
       " 'matio',\n",
       " ' cons',\n",
       " 'ns na',\n",
       " 'arnis',\n",
       " 'undle',\n",
       " 'ney b',\n",
       " 'lear:',\n",
       " 'nlist',\n",
       " 'ormou',\n",
       " 's, to',\n",
       " ' colo',\n",
       " 'ng, r',\n",
       " 'ic so',\n",
       " 's con',\n",
       " ' gain',\n",
       " 'urn r',\n",
       " ' hour',\n",
       " 'times',\n",
       " 'ans c',\n",
       " ' week',\n",
       " 'out, ',\n",
       " ' late',\n",
       " '- sum',\n",
       " 'knowl',\n",
       " 'ent. ',\n",
       " 'es li',\n",
       " 'emn a',\n",
       " 'ess b',\n",
       " ' will',\n",
       " 'sed b',\n",
       " ' lost',\n",
       " 'imes ',\n",
       " ' conf',\n",
       " 'bsurd',\n",
       " 'lied.',\n",
       " 'ort p',\n",
       " 'nge o',\n",
       " ' amy ',\n",
       " 'orita',\n",
       " 'e bat',\n",
       " 'somet',\n",
       " 'echoe',\n",
       " 'king ',\n",
       " 'eeks ',\n",
       " 'tarie',\n",
       " 'g hot',\n",
       " 'idenc',\n",
       " 'ze co',\n",
       " ' perh',\n",
       " 'e con',\n",
       " 'eous ',\n",
       " 'hout ',\n",
       " 'ply j',\n",
       " 'e tol',\n",
       " 'te at',\n",
       " 'y fil',\n",
       " '. tho',\n",
       " 'ials,',\n",
       " \"'s bl\",\n",
       " 'worke',\n",
       " 'te le',\n",
       " ' madn',\n",
       " 'wledg',\n",
       " 'erse ',\n",
       " ' circ',\n",
       " 'nstit',\n",
       " 'belie',\n",
       " 'mp \"a',\n",
       " 'awsui',\n",
       " 'lts. ',\n",
       " 'in fi',\n",
       " 'large',\n",
       " 't joe',\n",
       " 'repub',\n",
       " 'cknow',\n",
       " 'nt, b',\n",
       " 'summa',\n",
       " 'inal ',\n",
       " 'ired ',\n",
       " 'choed',\n",
       " 'law o',\n",
       " 'racti',\n",
       " 'schem',\n",
       " 'an pa',\n",
       " 'law. ',\n",
       " ' arou',\n",
       " 'ously',\n",
       " 'rly t',\n",
       " 's off',\n",
       " 'uisia',\n",
       " 'ed ar',\n",
       " 'ps to',\n",
       " 'most ',\n",
       " 'email',\n",
       " ' unan',\n",
       " 'e, le',\n",
       " 'erous',\n",
       " 'nce c',\n",
       " 'ble a',\n",
       " 'ointm',\n",
       " ' -- c',\n",
       " 'respe',\n",
       " 'ily d',\n",
       " ' outr',\n",
       " 'eme c',\n",
       " ' cong',\n",
       " ' ever',\n",
       " 'in 24',\n",
       " 's act',\n",
       " 'gregi',\n",
       " 'aciou',\n",
       " 's din',\n",
       " 'ice a',\n",
       " 'ourtr',\n",
       " 'ccurr',\n",
       " 'cans ',\n",
       " ' time',\n",
       " 'd res',\n",
       " 'hed w',\n",
       " 'w. ju',\n",
       " 'disho',\n",
       " '. fed',\n",
       " 'enge ',\n",
       " 'ght.s',\n",
       " 'ounts',\n",
       " 'hange',\n",
       " 'rs ho',\n",
       " 'rican',\n",
       " 'g, su',\n",
       " ' sche',\n",
       " 'dges ',\n",
       " 'te el',\n",
       " '-- mi',\n",
       " ' join',\n",
       " 'ned t',\n",
       " 'justi',\n",
       " 'otic ',\n",
       " 'ral j',\n",
       " 'ss co',\n",
       " 'ts co',\n",
       " 'en el',\n",
       " 'ven c',\n",
       " 'ed bo',\n",
       " 'reers',\n",
       " 'dence',\n",
       " 'ns sh',\n",
       " ', giv',\n",
       " 'democ',\n",
       " ', beh',\n",
       " 'nald ',\n",
       " 'ntena',\n",
       " 'trans',\n",
       " 'ossed',\n",
       " 'animo',\n",
       " 'ent.a',\n",
       " 'e gra',\n",
       " 'age e',\n",
       " 't, be',\n",
       " 'ent d',\n",
       " 'tion ',\n",
       " 'y kno',\n",
       " 'it st',\n",
       " 'son g',\n",
       " ' mobs',\n",
       " 'ethel',\n",
       " 'hreat',\n",
       " 'ge el',\n",
       " '. tim',\n",
       " 'ist\" ',\n",
       " \"t's s\",\n",
       " 'ound ',\n",
       " ', amo',\n",
       " 'n cle',\n",
       " 'nth-h',\n",
       " 'ds me',\n",
       " 'ost. ',\n",
       " 'anxio',\n",
       " 'cours',\n",
       " 'dness',\n",
       " 'mousl',\n",
       " ' hand',\n",
       " ' made',\n",
       " 'base,',\n",
       " 'refus',\n",
       " 'us co',\n",
       " 'ne un',\n",
       " 'esper',\n",
       " '.  \"l',\n",
       " 'trial',\n",
       " 'ours,',\n",
       " 'ade c',\n",
       " 'y job',\n",
       " ' four',\n",
       " ' amer',\n",
       " 'knowi',\n",
       " ' cert',\n",
       " 'icus ',\n",
       " 'folly',\n",
       " 'ne fa',\n",
       " 'etime',\n",
       " 'stem ',\n",
       " 'tract',\n",
       " 'fused',\n",
       " 'l set',\n",
       " ' 100 ',\n",
       " 'eryda',\n",
       " 'ge, a',\n",
       " 'amicu',\n",
       " ', wan',\n",
       " 'credi',\n",
       " 'k -- ',\n",
       " 'ing h',\n",
       " 's man',\n",
       " 'cus b',\n",
       " 'ousan',\n",
       " 'h-hou',\n",
       " 'ly ec',\n",
       " ' legi',\n",
       " 'd man',\n",
       " 'rushi',\n",
       " 'rhaps',\n",
       " 'als, ',\n",
       " 'party',\n",
       " ' grou',\n",
       " 'ote f',\n",
       " 'oor r',\n",
       " \"th's \",\n",
       " 'mocra',\n",
       " 'rn co',\n",
       " 'titut',\n",
       " 'suits',\n",
       " 'rs tr',\n",
       " 'd ema',\n",
       " 'usand',\n",
       " 'ws po',\n",
       " 'ump -',\n",
       " 'y dis',\n",
       " 'vativ',\n",
       " 've gr',\n",
       " 'e. pe',\n",
       " 'four ',\n",
       " 'ed co',\n",
       " 'd clo',\n",
       " 'mong ',\n",
       " 'team ',\n",
       " 'd sta',\n",
       " 'ng fr',\n",
       " 'on, p',\n",
       " 'votes',\n",
       " 'erver',\n",
       " 'espec',\n",
       " 'ge ba',\n",
       " 'vertu',\n",
       " 'meekl',\n",
       " 'ted s',\n",
       " '. doz',\n",
       " 's cra',\n",
       " '-- ho',\n",
       " 'ey ba',\n",
       " \"p's b\",\n",
       " 'e bid',\n",
       " 'geous',\n",
       " 'imous',\n",
       " 'crats',\n",
       " '. sui',\n",
       " 'ans d',\n",
       " 'ost j',\n",
       " 'nce, ',\n",
       " 'acts ',\n",
       " ' comp',\n",
       " ' rudy',\n",
       " 'd tru',\n",
       " 'inks ',\n",
       " 'g dir',\n",
       " 'igns ',\n",
       " ' ackn',\n",
       " 'battl',\n",
       " 'd cos',\n",
       " 'any s',\n",
       " 'rs co',\n",
       " 'dent-',\n",
       " ' bow ',\n",
       " ' hous',\n",
       " 'le el',\n",
       " 'torne',\n",
       " 'lect ',\n",
       " 'age. ',\n",
       " 'on lo',\n",
       " 'ertur',\n",
       " 'udaci',\n",
       " 'ats v',\n",
       " 'aw ti',\n",
       " 'ed ni',\n",
       " 'ity r',\n",
       " 'e fra',\n",
       " 'east)',\n",
       " 'month',\n",
       " 'ok le',\n",
       " 'ting ',\n",
       " 'rmati',\n",
       " '-- ev',\n",
       " 'ts pu',\n",
       " 'usly ',\n",
       " '. pat',\n",
       " 'filed',\n",
       " 'ttle ',\n",
       " ' bait',\n",
       " 'zy, a',\n",
       " 'ious ',\n",
       " 'spute',\n",
       " 'halle',\n",
       " 'ratif',\n",
       " ' laws',\n",
       " 'madne',\n",
       " 'thous',\n",
       " 'age d',\n",
       " 't,\" s',\n",
       " 'ce.he',\n",
       " 'n par',\n",
       " 'can m',\n",
       " 'mic s',\n",
       " 'l jud',\n",
       " 'ce re',\n",
       " 'olden',\n",
       " ' summ',\n",
       " 'ty, d',\n",
       " 'ory s',\n",
       " ' less',\n",
       " 'ear: ',\n",
       " 'also ',\n",
       " 'ay st',\n",
       " 'waiti',\n",
       " 'ing s',\n",
       " ' demo',\n",
       " 'ials ',\n",
       " 'gal s',\n",
       " 'other',\n",
       " 'cials',\n",
       " 'e.  \"',\n",
       " '. off',\n",
       " 'mp go',\n",
       " 'g sig',\n",
       " 'spera',\n",
       " 'ople ',\n",
       " ' priz',\n",
       " 'e out',\n",
       " 'ssed ',\n",
       " ' upen',\n",
       " 'ndemi',\n",
       " 's ack',\n",
       " 'ans n',\n",
       " 'on si',\n",
       " 'n 24 ',\n",
       " 'ine d',\n",
       " 'acy. ',\n",
       " 't, bl',\n",
       " 'gener',\n",
       " 'ointe',\n",
       " 'ans w',\n",
       " 'delay',\n",
       " 'te. s',\n",
       " 'mplic',\n",
       " 'rity ',\n",
       " 'es su',\n",
       " 'nine ',\n",
       " 'n. si',\n",
       " 'rybod',\n",
       " 'ful e',\n",
       " 'on wr',\n",
       " 'st eg',\n",
       " 'ked a',\n",
       " 'ystem',\n",
       " 'stero',\n",
       " ' weat',\n",
       " 'unnin',\n",
       " 's lat',\n",
       " 'ault ',\n",
       " 't lie',\n",
       " ' far ',\n",
       " 'ule e',\n",
       " 'ast m',\n",
       " 'g cou',\n",
       " 'ous o',\n",
       " 'ettin',\n",
       " 'deman',\n",
       " 'ding,',\n",
       " 'ficia',\n",
       " 'aud. ',\n",
       " 'e sen',\n",
       " 'ion d',\n",
       " 'e hou',\n",
       " 'fetim',\n",
       " 'es, l',\n",
       " 'ney g',\n",
       " 'nces ',\n",
       " 'd.and',\n",
       " 's sup',\n",
       " 'nywhe',\n",
       " 'r, cr',\n",
       " 'e cha',\n",
       " 's, re',\n",
       " 'essed',\n",
       " 's rig',\n",
       " ' unco',\n",
       " 'r. se',\n",
       " ' amic',\n",
       " 'ous c',\n",
       " 'taria',\n",
       " 'ked c',\n",
       " 'genui',\n",
       " 'ally.',\n",
       " 'te pe',\n",
       " \"'s ba\",\n",
       " 'ired.',\n",
       " 'g sid',\n",
       " 'resul',\n",
       " 'e ref',\n",
       " 'y sco',\n",
       " 's del',\n",
       " 'ularl',\n",
       " 'fensi',\n",
       " 'd ins',\n",
       " 'se re',\n",
       " 'ndemn',\n",
       " '- sta',\n",
       " 'one f',\n",
       " ' mont',\n",
       " 'urged',\n",
       " '(so f',\n",
       " 'ortin',\n",
       " '\" see',\n",
       " 'ime t',\n",
       " '-elec',\n",
       " 'hope ',\n",
       " 'tate ',\n",
       " 'idst ',\n",
       " 'g abs',\n",
       " 'es, s',\n",
       " 'urs, ',\n",
       " 'feder',\n",
       " 'te, d',\n",
       " 'askin',\n",
       " 'latan',\n",
       " ' repu',\n",
       " 'ered ',\n",
       " 'rmous',\n",
       " 'rt co',\n",
       " '. non',\n",
       " 'so fa',\n",
       " 'cy de',\n",
       " 'ange ',\n",
       " 'urn e',\n",
       " 'egiou',\n",
       " 't\" se',\n",
       " 'backg',\n",
       " 'ged r',\n",
       " 'd bow',\n",
       " 'racy ',\n",
       " 'conte',\n",
       " 'omeho',\n",
       " 'lity ',\n",
       " 'conti',\n",
       " 'neral',\n",
       " 'ote s',\n",
       " 'ely r',\n",
       " 'on, r',\n",
       " 'l lis',\n",
       " 't ano',\n",
       " 'en cr',\n",
       " 'ernme',\n",
       " 'razy,',\n",
       " 'ryday',\n",
       " ' star',\n",
       " 'yet m',\n",
       " 'e tar',\n",
       " 'udges',\n",
       " 'rging',\n",
       " 't mad',\n",
       " 'mpt u',\n",
       " 's tru',\n",
       " \"et's \",\n",
       " 'ities',\n",
       " 'r rej',\n",
       " 'istor',\n",
       " 'onest',\n",
       " ' beho',\n",
       " ', sup',\n",
       " ' dela',\n",
       " 'our f',\n",
       " 'fidel',\n",
       " 'nt-el',\n",
       " 'enera',\n",
       " 'rn el',\n",
       " 'ls ri',\n",
       " 'e, am',\n",
       " 'imply',\n",
       " ' dona',\n",
       " 'eleve',\n",
       " 'ost e',\n",
       " 'na ci',\n",
       " 'ion a',\n",
       " 'erson',\n",
       " 'occur',\n",
       " 's dem',\n",
       " 'demic',\n",
       " 'arret',\n",
       " 'andem',\n",
       " 'ctory',\n",
       " 'prepo',\n",
       " ' cont',\n",
       " 'dozen',\n",
       " 'start',\n",
       " 'd pre',\n",
       " 't) en',\n",
       " ' anyw',\n",
       " 'nderm',\n",
       " 'n sta',\n",
       " 'utrag',\n",
       " 'coura',\n",
       " 'icial',\n",
       " ' perv',\n",
       " ' acts',\n",
       " 'where',\n",
       " 'h, ev',\n",
       " 's wou',\n",
       " 'nimou',\n",
       " '- hon',\n",
       " 'ump l',\n",
       " 'room,',\n",
       " 'racy.',\n",
       " '. rud',\n",
       " 'e bai',\n",
       " 'ompli',\n",
       " 'based',\n",
       " 'half.',\n",
       " 'cowar',\n",
       " 'gness',\n",
       " 'e, di',\n",
       " 'aign ',\n",
       " 'round',\n",
       " 'signs',\n",
       " 'ple p',\n",
       " 'ssion',\n",
       " 'ct bi',\n",
       " '\"let\\'',\n",
       " '.secr',\n",
       " 'aries',\n",
       " 'use t',\n",
       " 'fice.',\n",
       " 'se se',\n",
       " 'rote,',\n",
       " 'verno',\n",
       " 'heles',\n",
       " 'use c',\n",
       " 'so se',\n",
       " 't-ele',\n",
       " 'iotic',\n",
       " 'nuati',\n",
       " 'troom',\n",
       " 'suit ',\n",
       " 'ed of',\n",
       " 'overn',\n",
       " 'pirin',\n",
       " ' over',\n",
       " 'ail s',\n",
       " 'y sho',\n",
       " 's vot',\n",
       " 'd wee',\n",
       " 'es st',\n",
       " 'major',\n",
       " 'ly ca',\n",
       " '. wit',\n",
       " 'us of',\n",
       " 'ant h',\n",
       " 'l lin',\n",
       " ', wit',\n",
       " 'ppoin',\n",
       " 'ies c',\n",
       " '. sup',\n",
       " 'ge ou',\n",
       " 'ranch',\n",
       " 'ndful',\n",
       " 'sture',\n",
       " 'ves -',\n",
       " 'turn ',\n",
       " 'w. tr',\n",
       " 'p \"an',\n",
       " 't, to',\n",
       " ...}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_shingles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:19:07.279060Z",
     "start_time": "2021-06-07T15:19:07.270959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shingle of doc 1 example : \n",
      "['far a', 'e maj', 'ecede', 'reats', 'onall']\n",
      "[[4 1]\n",
      " [2 2]]\n",
      "[[4 1]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "# shingle = 5\n",
    "# shingle_dict\n",
    "# len(doc_shingles[0])\n",
    "############ Examples #############\n",
    "# https://numpy.org/doc/1.20/reference/generated/numpy.dot.html?highlight=dot#numpy.dot\n",
    "\n",
    "# a @ b means a, b are two dimentional matrix,\n",
    "# and the result is the same as np.dot(a,b)\n",
    "\n",
    "a = np.array([[1, 0], [0, 1]])\n",
    "b = np.array([[4, 1], [2, 2]])\n",
    "\n",
    "\n",
    "print(\n",
    "    'shingle of doc 1 example : ',\n",
    "    list(doc_shingles[0])[:5],\n",
    "    np.dot(a,b),\n",
    "    a @ b,\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:52:19.907457Z",
     "start_time": "2021-06-07T15:52:19.744151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initilization\n",
      "passed\n",
      "parametets is the right shape\n",
      "passed\n",
      "permuting a row integer returns array\n",
      "passed\n",
      "Compute minhashed signature matrix : \n",
      "passed\n"
     ]
    }
   ],
   "source": [
    "# Create a hash function\n",
    "# define as a callable class, so that we only initialize \n",
    "# random function once\n",
    "# This is only Minhasher\n",
    "\n",
    "class HashManager():\n",
    "    def __init__(self, shingle_dict : dict, n_signature : int) -> None:\n",
    "        self.shingle_dict = shingle_dict\n",
    "        self.N = len(shingle_dict)\n",
    "        self.n_signature = n_signature\n",
    "        # create random integer from zero to N\n",
    "        # TODO\n",
    "        self.params = np.random.randint(self.N,\n",
    "                                        size=[n_signature, 2])\n",
    "    \n",
    "    def _permuteRow(self, row):\n",
    "        # TODO\n",
    "        return self.params @ np.array([1, row]) % self.N\n",
    "    \n",
    "    def __call__(self, docs):\n",
    "        \n",
    "        # initialize signature matrix\n",
    "        sig = np.full(\n",
    "            (self.n_signature, len(docs)),\n",
    "             np.inf\n",
    "            )\n",
    "        \n",
    "        # each doc in docs is assumed to be an iterable object\n",
    "        # we hash all the docs into signature matrix\n",
    "        for doc_i, doc in enumerate(docs):\n",
    "            for shingle in doc:\n",
    "#                 print(list(doc)[:5], shingle)\n",
    "                orig_row = shingle_dict[shingle]\n",
    "                curr_col = self._permuteRow(orig_row)\n",
    "                sig[:, doc_i] = np.minimum(\n",
    "                    sig[:, doc_i],\n",
    "                    curr_col\n",
    "                )\n",
    "        return sig.astype(int)\n",
    "    \n",
    "# run some tests\n",
    "\n",
    "try:\n",
    "    n_signature = 100\n",
    "    print(\"Initilization\")\n",
    "    min_hasher = HashManager(shingle_dict,\n",
    "                             n_signature=n_signature)\n",
    "    print(\"passed\")\n",
    "    \n",
    "    print('parametets is the right shape')\n",
    "    assert(min_hasher.params.shape == (n_signature, 2))\n",
    "    print('passed')\n",
    "    \n",
    "    print(\"permuting a row integer returns array\")\n",
    "    curr_col = min_hasher._permuteRow(3)\n",
    "    assert(curr_col.shape == (n_signature, ))\n",
    "    print('passed')\n",
    "    \n",
    "    print(\"Compute minhashed signature matrix : \")\n",
    "    res = min_hasher(doc_shingles)\n",
    "    assert res.shape == (n_signature, len(doc_shingles))\n",
    "    print(\"passed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:52:21.435936Z",
     "start_time": "2021-06-07T15:52:21.421760Z"
    }
   },
   "outputs": [],
   "source": [
    "def trueSimScores(doc_shingles):\n",
    "    pair_labels = []\n",
    "    pair_sims = []\n",
    "    idxs = range(len(doc_shingles))\n",
    "    for x1, x2 in itertools.combinations(zip(idxs,doc_shingles), 2):\n",
    "        pair_labels.append((x1[0], x2[0]))\n",
    "        pair_sims.append(jaccardSim(x1[1], x2[1]))\n",
    "    return dict(zip(pair_labels, pair_sims))\n",
    "    \n",
    "def sigSimScores(sig_mat):\n",
    "#     cols = [sig_mat[:,i] for i in range(sig_mat.shape[1])]\n",
    "    cols = sig_mat.T\n",
    "    idxs = range(sig_mat.shape[1])\n",
    "    \n",
    "    pair_labels = []\n",
    "    pair_sims = []\n",
    "    for (i,col1), (j,col2) in itertools.combinations(zip(idxs, cols),2):\n",
    "        pair_labels.append((i,j))\n",
    "        pair_sims.append(np.mean(col1==col2))\n",
    "    \n",
    "    return dict(zip(pair_labels, pair_sims))\n",
    "\n",
    "def printScoreComparison(true_dict, approx_dict):\n",
    "    print(f\"**~~~~~~ Similarity score comparison ~~~~~~**\")\n",
    "    print(\"Pair\\t\\tApprox\\t\\tTrue\\t\\t%Error\")\n",
    "    for pair, true_value in true_dict.items():\n",
    "        approx_value = approx_dict[pair]\n",
    "        err = 100*abs(true_value-approx_value)/true_value\n",
    "        print(f\"{pair}\\t\\t{approx_value:.3f}\\t\\t{true_value:.3f}\\t\\t{err:.2f}\")\n",
    "\n",
    "def candidatePairs(score_dict, threshold):\n",
    "    return set(pair for pair, scr in score_dict.items() if scr>=threshold)\n",
    "\n",
    "def accMatrix(true_dict, approx_dict, threshold):\n",
    "    true_pairs = candidatePairs(true_dict, threshold)\n",
    "    approx_pairs = candidatePairs(approx_dict, threshold)\n",
    "    false_negatives = len(true_pairs - approx_pairs)\n",
    "    false_positives = len(approx_pairs - true_pairs)\n",
    "    print(f\"False negatives: {false_negatives}\")\n",
    "    print(f\"Potential false positives: {false_positives}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:53:15.301123Z",
     "start_time": "2021-06-07T15:53:15.170229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**~~~~~~ Similarity score comparison ~~~~~~**\n",
      "Pair\t\tApprox\t\tTrue\t\t%Error\n",
      "(0, 1)\t\t0.200\t\t0.081\t\t147.01\n",
      "(0, 2)\t\t0.200\t\t0.052\t\t286.93\n",
      "(0, 3)\t\t0.300\t\t0.083\t\t261.57\n",
      "(0, 4)\t\t0.200\t\t0.069\t\t190.38\n",
      "(1, 2)\t\t0.200\t\t0.051\t\t289.08\n",
      "(1, 3)\t\t0.350\t\t0.294\t\t18.85\n",
      "(1, 4)\t\t0.200\t\t0.093\t\t114.52\n",
      "(2, 3)\t\t0.350\t\t0.400\t\t12.54\n",
      "(2, 4)\t\t0.050\t\t0.050\t\t0.24\n",
      "(3, 4)\t\t0.450\t\t0.336\t\t33.84\n",
      "True pairs: {(3, 4), (1, 3), (2, 3)}\n",
      "Candidate pairs: {(3, 4), (0, 3), (1, 3), (2, 3)}\n",
      "False negatives: 1\n",
      "Potential false positives: 1\n"
     ]
    }
   ],
   "source": [
    "min_hasher = HashManager(shingle_dict,\n",
    "                             n_signature=20)\n",
    "\n",
    "sig_mat = min_hasher(doc_shingles)\n",
    "true_score_dict = trueSimScores(doc_shingles)\n",
    "approx_score_dict = sigSimScores(sig_mat)\n",
    "printScoreComparison(true_score_dict, approx_score_dict)\n",
    "\n",
    "print(\"True pairs:\",candidatePairs(true_score_dict, 0.25))\n",
    "print(\"Candidate pairs:\",candidatePairs(approx_score_dict, 0.25))\n",
    "accMatrix(true_score_dict, approx_score_dict, 0.4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_tf231",
   "language": "python",
   "name": "py37_tf231"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
